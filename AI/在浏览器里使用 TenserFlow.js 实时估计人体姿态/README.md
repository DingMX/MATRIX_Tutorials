## 在浏览器里使用 TenserFlow.js 实时估计人体姿态

在与谷歌创意实验室的合作中，我很高兴地宣布 TensorFlow.js 版 PoseNet¹ 的发行，² 它是一个能够在浏览器里对人体姿态进行实时估计的机器学习模型。[点击这里](https://link.juejin.im/?target=https%3A%2F%2Fstorage.googleapis.com%2Ftfjs-models%2Fdemos%2Fposenet%2Fcamera.html)在线体验。



![](https://user-gold-cdn.xitu.io/2018/5/17/1636e48abc1dcc79?imageslim)

![](https://user-gold-cdn.xitu.io/2018/5/17/1636e48520989173?imageslim)

PoseNet 使用单人姿态或多人姿态算法可以检测图像和视频中的人物形象 —— 全部在浏览器中完成。

那么，姿态估计究竟是什么呢？姿态估计是指在图像和视频中检测人物的计算机视觉技术，比如，可以确定某个人的肘部在图像中的位置。需要澄清一点，这项技术并不是识别图像中是谁 —— 姿态估计不涉及任何个人身份信息。该算法仅仅是估计身体关键关节的位置。

好吧，为什么这是令人兴奋的开始？姿态估计有很多用途，从互动装置反馈给身体，到增强现实，动画，健身用途等等。我们希望借助此模型激发更多的开发人员和制造商尝试将姿态检测应用到他们自己的独特项目中。虽然许多同类姿态检测系统也已经开源，但它们都需要专门的硬件和/或相机，以及相当多的系统安装。 借助运行在 TensorFlow.js 上的 PoseNet，任何人只需拥有带摄像头的台式机或者手机即可在浏览器中体验这项技术。而且由于我们已经开源了这个模型，JavaScript 开发人员可以用几行代码来修改和使用这个技术。更重要的是，这实际上可以帮助保护用户隐私。因为基于 TensorFlow.js 的 PoseNet 运行在浏览器中，任何姿态数据都不会离开用户的计算机。






### PoseNet 入门

PoseNet 可以被用来估计单人姿态或多人姿态，这意味着算法有一个检测图像/视频中只有一个人的版本，和检测多人的版本。为什么会有两个版本？因为单人姿态检测更快，更简单，但要求图像中只能有一个主体（后面会详细说明）。我们先说单体姿态，因为它更简单易懂。

姿态估计整体来看主要有两个阶段：

- 输入一个通过卷积神经网络反馈的 RGB 图像。

- 使用单人姿态或多人姿态解码算法从模型输出中解码姿态，姿态置信得分，关键点位置，以及关键点置信得分。

等一下，所有这些关键词指的是什么？我们看看一下最重要的几个：

姿态 - 从最上层来看，PoseNet 将返回一个姿态对象，其中包含每个检测到的人物的关键点列表和实例级别的置信度分数。

![](https://user-gold-cdn.xitu.io/2018/5/17/1636e4850f000924?imageslim)

PoseNet 返回检测到的每个人的置信度值以及检测到的每个姿态关键点。

- 姿态置信度分数 - 决定了对姿态估计的整体置信度。它介于 0.0 和 1.0 之间。它可以用来隐藏分数不够高的姿态。
- 关键点 —— 估计的人体姿态的一部分，例如鼻子，右耳，左膝，右脚等。 它包含位置和关键点置信度分数。PoseNet 目前检测到下图所示的 17 个关键点：



![](https://user-gold-cdn.xitu.io/2018/5/17/1636e485bb9b88f2?imageslim)


PosNet 检测到17个姿态关键点。

- 关键点置信度得分 - 决定了估计关键点位置准确的置信度。它介于 0.0 和 1.0 之间。它可以用来隐藏分数不够高的关键点。
- 关键点位置 —— 检测到关键点的原始输入图像中的二维 x 和 y 坐标。